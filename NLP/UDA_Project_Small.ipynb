{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This Jupyter Notebook is designed to analyze and recommend restaurants based on taste profiles extracted from Yelp reviews. The workflow involves several key steps:\n",
    "\n",
    "1. **Data Preparation**:\n",
    "    - Import necessary libraries and modules.\n",
    "    - Define the `TasteProfile` class to encapsulate various taste, texture, dietary, and ambiance dimensions.\n",
    "    - Download necessary NLTK resources for text processing.\n",
    "\n",
    "2. **Taste Profile Analysis**:\n",
    "    - Define methods to update taste profiles based on review text.\n",
    "    - Extract mentions of different taste, texture, dietary, and ambiance aspects from reviews.\n",
    "    - Analyze sentiment of review text to adjust scores accordingly.\n",
    "\n",
    "3. **Review Processing**:\n",
    "    - Process a list of sample reviews to update the taste profile.\n",
    "    - View the current taste profile and recommend top restaurants based on cuisine parameters.\n",
    "    - Define hyper-specific cuisine profiles for various cuisines like Italian, Mexican, Japanese, etc.\n",
    "\n",
    "4. **Yelp Data Analysis**:\n",
    "    - Define the `YelpAnalyzer` class to handle Yelp data analysis.\n",
    "    - Implement methods to load, filter, clean, and analyze Yelp data.\n",
    "    - Extract and analyze taste profiles, perform clustering, and validate results.\n",
    "\n",
    "5. **Recommendations and Similarity**:\n",
    "    - Recommend top 10 restaurants based on cuisine profiles.\n",
    "    - Find the 10 most similar dishes to the initialized taste profile.\n",
    "\n",
    "The notebook leverages NLP techniques, sentiment analysis, and clustering algorithms to provide insights and recommendations based on user reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/msgfrom96/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List\n",
    "from transformers import pipeline\n",
    "from torch import cuda\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')  # Ensure the punkt tokenizer is downloaded\n",
    "\n",
    "@dataclass\n",
    "class TasteProfile:\n",
    "    # Core taste dimensions - all start at neutral 0.5\n",
    "    sweet: float = 0.5      \n",
    "    salty: float = 0.5      \n",
    "    spicy: float = 0.5      \n",
    "    savory: float = 0.5     \n",
    "    bitter: float = 0.5     \n",
    "    sour: float = 0.5 \n",
    "\n",
    "    # Texture dimensions - all start at neutral 0.5\n",
    "    crunchiness: float = 0.5\n",
    "    smoothness: float = 0.5\n",
    "    chewiness: float = 0.5\n",
    "    creaminess: float = 0.5\n",
    "    firmness: float = 0.5\n",
    "    juiciness: float = 0.5\n",
    "    softness: float = 0.5    \n",
    "    \n",
    "    # Dietary and health dimensions\n",
    "    gluten_free: float = 0.0\n",
    "    dairy_free: float = 0.0\n",
    "    vegan: float = 0.0\n",
    "    vegetarian: float = 0.0\n",
    "    nut_free: float = 0.0\n",
    "    shellfish_free: float = 0.0\n",
    "    price_sensitivity: float = 0.0\n",
    "    health_consciousness: float = 0.0\n",
    "    spice_tolerance: float = 0.0\n",
    "    sustainability_consciousness: float = 0.0\n",
    "    low_carb: float = 0.0\n",
    "    low_fat: float = 0.0\n",
    "    low_sugar: float = 0.0\n",
    "    organic: float = 0.0\n",
    "    halal: float = 0.0\n",
    "    kosher: float = 0.0\n",
    "    \n",
    "    # Ambiance and presentation - start at neutral 0.5\n",
    "    lighting_quality: float = 0.5\n",
    "    noise_level: float = 0.5\n",
    "    seating_comfort: float = 0.5\n",
    "    plating_aesthetics: float = 0.5\n",
    "    portion_size: float = 0.5\n",
    "    service_speed: float = 0.5\n",
    "    cleanliness: float = 0.5\n",
    "    temperature: float = 0.5\n",
    "    accessibility: float = 0.5\n",
    "    friendly_staff: float = 0.5\n",
    "    family_friendly: float = 0.5\n",
    "    romantic_ambiance: float = 0.5\n",
    "    cuisine_profiles: Dict[str, float] = field(default_factory=dict)  # Add this line, float] = field(default_factory=dict)  # Add this line\n",
    "\n",
    "\n",
    "    review_count: int = 0  # Counter for the number of reviews processed\n",
    "\n",
    "    def update_scores(self, review_text: str):\n",
    "        \"\"\"Update taste profile scores based on review text analysis\"\"\"\n",
    "        print(f\"Updating scores based on review: {review_text}\")\n",
    "        \n",
    "        # Split review into sentences\n",
    "        sentences = nltk.sent_tokenize(review_text)\n",
    "        \n",
    "        # Process each sentence individually\n",
    "        for sentence in sentences:\n",
    "            sentiment_scores = self._analyze_sentiment(sentence)\n",
    "            print(f\"Sentiment scores for sentence: {sentiment_scores}\")\n",
    "            \n",
    "            # Extract mentions and intensities for different aspects\n",
    "            taste_mentions = self._extract_taste_mentions(sentence)\n",
    "            texture_mentions = self._extract_texture_mentions(sentence)\n",
    "            dietary_mentions = self._extract_dietary_mentions(sentence)\n",
    "            ambiance_mentions = self._extract_ambiance_mentions(sentence)\n",
    "            \n",
    "            # Update all dimensions using the review count for weighting\n",
    "            self._update_scores(taste_mentions, 'taste', sentiment_scores)\n",
    "            self._update_scores(texture_mentions, 'texture', sentiment_scores)\n",
    "            self._update_scores(dietary_mentions, 'dietary', sentiment_scores)\n",
    "            self._update_scores(ambiance_mentions, 'ambiance', sentiment_scores)\n",
    "\n",
    "        # Increment the review count\n",
    "        self.review_count += 1\n",
    "\n",
    "    def _update_scores(self, mentions: List[tuple], category: str, sentiment_scores: dict):\n",
    "        \"\"\"Update scores based on mentions for a specific category\"\"\"\n",
    "        for aspect, match in mentions:\n",
    "            intensity = self._calculate_intensity(match, match.string, sentiment_scores)\n",
    "            current = getattr(self, aspect)\n",
    "            # Calculate the weight based on the number of reviews\n",
    "            weight = 1 / (self.review_count + 1)  # New review affects the score less as count increases\n",
    "            new_value = (weight * intensity) + ((1 - weight) * current)\n",
    "            # Adjust for negative sentiment if applicable\n",
    "            if sentiment_scores['negative'] > 0:\n",
    "                new_value = max(0.0, new_value - sentiment_scores['negative'])\n",
    "            setattr(self, aspect, min(max(new_value, 0.0), 1.0))\n",
    "            print(f\"Updated {aspect}: {current} -> {new_value}\")\n",
    "\n",
    "    def _analyze_sentiment(self, text: str) -> dict:\n",
    "        \"\"\"Analyze sentiment in review text\"\"\"\n",
    "        print(f\"Analyzing sentiment for text: {text}\")\n",
    "\n",
    "        # Initialize sentiment analysis pipeline\n",
    "        if TasteProfile._sentiment_pipeline is None:\n",
    "            TasteProfile._sentiment_pipeline = pipeline(\n",
    "                \"sentiment-analysis\",\n",
    "                model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "                device=0 if cuda.is_available() else \"cpu\"\n",
    "            )\n",
    "\n",
    "        # Get sentiment predictions\n",
    "        predictions = TasteProfile._sentiment_pipeline(text)\n",
    "\n",
    "        # Extract relevant scores and labels\n",
    "        sentiment_scores = {\n",
    "            \"positive\": 0.0,\n",
    "            \"negative\": 0.0,\n",
    "            \"neutral\": 0.0\n",
    "        }\n",
    "\n",
    "        # Analyze text for negative indicators\n",
    "        negative_indicators = [\"too much\", \"too little\", \"not very\", \"lacking\"]\n",
    "        has_negative = any(indicator in text.lower() for indicator in negative_indicators)\n",
    "\n",
    "        for prediction in predictions:\n",
    "            if has_negative and prediction['label'] == 'positive':\n",
    "                # Flip positive to negative if negative indicators present\n",
    "                sentiment_scores['negative'] = prediction['score']\n",
    "            else:\n",
    "                sentiment_scores[prediction['label']] = prediction['score']\n",
    "\n",
    "        return sentiment_scores\n",
    "\n",
    "    def _extract_mentions(self, text: str) -> List[tuple]:\n",
    "        \"\"\"Extract mentions of tastes, textures, ambiance, and health aspects with their intensities\"\"\"\n",
    "        taste_mentions = self._extract_taste_mentions(text)\n",
    "        texture_mentions = self._extract_texture_mentions(text)\n",
    "        ambiance_mentions = self._extract_ambiance_mentions(text)\n",
    "        health_mentions = self._extract_health_mentions(text)\n",
    "\n",
    "        return taste_mentions + texture_mentions + ambiance_mentions + health_mentions\n",
    "\n",
    "    def _extract_taste_mentions(self, text: str) -> List[tuple]:\n",
    "        \"\"\"Extract taste-related mentions and their intensities\"\"\"\n",
    "        keywords = self._get_keywords()[\"taste\"]\n",
    "        matches = []\n",
    "        for aspect, pattern in keywords.items():\n",
    "            if found := re.finditer(pattern, text, re.I):\n",
    "                for match in found:\n",
    "                    matches.append((aspect, match))\n",
    "        return matches\n",
    "\n",
    "    def _extract_texture_mentions(self, text: str) -> List[tuple]:\n",
    "        \"\"\"Extract texture-related mentions and their intensities\"\"\"\n",
    "        keywords = self._get_keywords()[\"texture\"]\n",
    "        matches = []\n",
    "        for aspect, pattern in keywords.items():\n",
    "            if found := re.finditer(pattern, text, re.I):\n",
    "                for match in found:\n",
    "                    matches.append((aspect, match))\n",
    "        return matches\n",
    "\n",
    "    def _extract_ambiance_mentions(self, text: str) -> List[tuple]:\n",
    "        \"\"\"Extract ambiance-related mentions and their intensities\"\"\"\n",
    "        keywords = self._get_keywords()[\"ambiance\"]\n",
    "        matches = []\n",
    "        for aspect, pattern in keywords.items():\n",
    "            if found := re.finditer(pattern, text, re.I):\n",
    "                for match in found:\n",
    "                    matches.append((aspect, match))\n",
    "        return matches\n",
    "\n",
    "    def _extract_dietary_mentions(self, text: str) -> List[tuple]:\n",
    "        \"\"\"Extract health-related mentions and their intensities\"\"\"\n",
    "        keywords = self._get_keywords()[\"health\"]\n",
    "        matches = []\n",
    "        for aspect, pattern in keywords.items():\n",
    "            if found := re.finditer(pattern, text, re.I):\n",
    "                for match in found:\n",
    "                    matches.append((aspect, match))\n",
    "        return matches\n",
    "\n",
    "    def _get_keywords(self) -> dict:\n",
    "        \"\"\"Return the keywords for different categories\"\"\"\n",
    "        return {\n",
    "            \"taste\": {\n",
    "                \"sweet\": r\"\\b(sweet|sugary|honeyed|fruity|cloying|maple|butterscotch)\\b\",\n",
    "                \"salty\": r\"\\b(salty|briny|savory)\\b\",\n",
    "                \"spicy\": r\"\\b(spicy|hot|peppery|fiery)\\b\",\n",
    "                \"savory\": r\"\\b(savory|umami|flavorful|tasty)\\b\",\n",
    "                \"bitter\": r\"\\b(bitter|acrid|sharp|harsh)\\b\",\n",
    "                \"sour\": r\"\\b(sour|tart|acidic|vinegary|citrusy)\\b\",\n",
    "            },\n",
    "            \"texture\": {\n",
    "                \"crunchiness\": r\"\\b(crunchy|crisp|soggy)\\b\",\n",
    "                \"smoothness\": r\"\\b(smooth|silky|creamy|buttery)\\b\",\n",
    "                \"chewiness\": r\"\\b(chewy|gummy|tender|elastic)\\b\",\n",
    "                \"creaminess\": r\"\\b(creamy|rich|thick|watery)\\b\",\n",
    "                \"firmness\": r\"\\b(firm|solid|sturdy|dense)\\b\",\n",
    "                \"juiciness\": r\"\\b(juicy|succulent|moist|dry)\\b\",\n",
    "                \"softness\": r\"\\b(soft|tender|fluffy|light)\\b\",\n",
    "            },\n",
    "            \"ambiance\": {\n",
    "                \"lighting_quality\": r\"\\blighting\\b\",\n",
    "                \"noise_level\": r\"\\b(noisy|quiet|loud|silent|hushed|cacophonous|muffled|boisterous|calm)\\b\",\n",
    "                \"seating_comfort\": r\"\\b(comfortable|uncomfortable|cozy|cramped|spacious|tight|relaxing|uninviting|plush|hard)\\b\",\n",
    "                \"plating_aesthetics\": r\"\\b(plating|presentation|arrangement|display|garnish|decor)\\b\",\n",
    "                \"portion_size\": r\"\\b(portion|serving|helping|quantity|size|amount)\\b\",\n",
    "                \"service_speed\": r\"\\b(speed|slow|quick|prompt|leisurely|fast|delayed|efficient|inefficient)\\b\",\n",
    "                \"cleanliness\": r\"\\b(clean|dirty|spotless|filthy|neat|messy|pristine|unclean|tidy|disheveled)\\b\",\n",
    "                \"temperature\": r\"\\b(temperature|hot|cold|warm|chilly|cool|scalding|freezing|tepid)\\b\",\n",
    "                \"accessibility\": r\"\\b(accessible|inaccessible|convenient|difficult|easy|hard|user-friendly|barrier-free)\\b\",\n",
    "                \"friendly_staff\": r\"\\b(friendly|unfriendly|welcoming|hostile|polite|rude|approachable|dismissive|attentive|indifferent)\\b\",\n",
    "                \"family_friendly\": r\"\\b(family|child-friendly|adult-only|kid-friendly|family-oriented|inclusive|welcoming|safe)\\b\",\n",
    "                \"romantic_ambiance\": r\"\\b(romantic|intimate|cozy|cold|unromantic|passionate|lovely|charming|affectionate|sentimental)\\b\",\n",
    "            },\n",
    "            \"health\": {\n",
    "                \"gluten_free\": r\"\\b(gluten free|gluten-free|without gluten|no gluten|glutenless)\\b\",\n",
    "                \"dairy_free\": r\"\\b(dairy free|dairy-free|lactose free|lactose-free|without dairy|no dairy|dairyless)\\b\",\n",
    "                \"vegan\": r\"\\b(vegan|plant-based|animal-free|no animal products|plant derived)\\b\",\n",
    "                \"vegetarian\": r\"\\b(vegetarian|meat-free|no meat|meatless|non-meat)\\b\",\n",
    "                \"nut_free\": r\"\\b(nut free|nut-free|without nuts|no nuts|nutless)\\b\",\n",
    "                \"shellfish_free\": r\"\\b(shellfish free|shellfish-free|without shellfish|no shellfish|shellfishless)\\b\",\n",
    "                \"price_sensitivity\": r\"\\b(price|cost-sensitive|budget-conscious|affordable|inexpensive|expensive|pricey)\\b\",\n",
    "                \"health_consciousness\": r\"\\b(healthy|nutritious|wellness|fit|unhealthy|harmful|health-aware|health-focused)\\b\",\n",
    "                \"spice_tolerance\": r\"\\b(spicy|mild|hot|bland|spiced|seasoned)\\b\",\n",
    "                \"sustainability_consciousness\": r\"\\b(sustainable|eco-friendly|unsustainable|harmful to the environment|green|environmentally friendly)\\b\",\n",
    "                \"low_carb\": r\"\\b(low carb|low-carbohydrate|high carb|carb-heavy|carb-light|reduced carb)\\b\",\n",
    "                \"low_fat\": r\"\\b(low fat|low-fat|high fat|fatty|reduced fat|light fat)\\b\",\n",
    "                \"low_sugar\": r\"\\b(low sugar|low-sugar|high sugar|sugary|sugar-free|no sugar)\\b\",\n",
    "                \"organic\": r\"\\b(organic|non-organic|chemical-free|natural)\\b\",\n",
    "                \"halal\": r\"\\b(halal|non-halal)\\b\",\n",
    "                \"kosher\": r\"\\b(kosher|non-kosher|treif|glatt|permitted)\\b\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Sentiment pipeline instance shared across all instances\n",
    "    _sentiment_pipeline = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Initialize the sentiment pipeline if not already done\"\"\"\n",
    "        if TasteProfile._sentiment_pipeline is None:\n",
    "            TasteProfile._sentiment_pipeline = pipeline(\n",
    "                \"sentiment-analysis\",\n",
    "                model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "                device=0 if cuda.is_available() else \"cpu\"\n",
    "            )\n",
    "\n",
    "    def update_from_review(self, review_text: str, alpha: float = 0.3) -> None:\n",
    "        \"\"\"Update profile based on a single review\"\"\"\n",
    "        print(f\"Updating from review: {review_text}\")\n",
    "        # Clean text\n",
    "        review_text = review_text.lower().strip()\n",
    "        \n",
    "        # Get sentiment\n",
    "        sentiment = self._get_sentiment(review_text)\n",
    "        print(f\"Sentiment score: {sentiment}\")\n",
    "        \n",
    "        # Update dimensions based on keyword matches\n",
    "        for category, patterns in self._get_keywords().items():\n",
    "            for aspect, pattern in patterns.items():\n",
    "                if matches := re.finditer(pattern, review_text, re.I):\n",
    "                    for match in matches:\n",
    "                        intensity = self._calculate_intensity(match, review_text, sentiment)\n",
    "                        current = getattr(self, aspect)\n",
    "                        # Calculate the weight based on the number of reviews\n",
    "                        weight = 1 / (self.review_count + 1)  # New review affects the score less as count increases\n",
    "                        new_value = (weight * intensity) + ((1 - weight) * current)\n",
    "                        setattr(self, aspect, min(max(new_value, 0.0), 1.0))\n",
    "                        print(f\"Updated {aspect}: {current} -> {new_value}\")\n",
    "\n",
    "    def _get_sentiment(self, text: str) -> float:\n",
    "        \"\"\"Get sentiment score from -1 to 1\"\"\"\n",
    "        result = self._sentiment_pipeline(text)[0]\n",
    "        if result[\"label\"] == \"positive\":\n",
    "            return result[\"score\"]\n",
    "        elif result[\"label\"] == \"negative\":\n",
    "            return -result[\"score\"]\n",
    "        return 0.0\n",
    "\n",
    "    def _calculate_intensity(self, match: re.Match, text: str, sentiment_scores: dict) -> float:\n",
    "        \"\"\"Calculate intensity of a match based on context and sentiment\"\"\"\n",
    "        # Get surrounding context\n",
    "        start, end = match.span()\n",
    "        context = text[max(0, start-20):min(len(text), end+20)]\n",
    "        \n",
    "        # Base intensity from sentiment\n",
    "        intensity = abs(sentiment_scores['positive'] - sentiment_scores['negative'])\n",
    "        \n",
    "        # Boost for intensifiers\n",
    "        intensifiers = [\"very\", \"really\", \"extremely\", \"super\"]\n",
    "        if any(i in context for i in intensifiers):\n",
    "            intensity *= 1.5\n",
    "            \n",
    "        return min(intensity, 1.0)\n",
    "\n",
    "    def to_dict(self) -> Dict[str, float]:\n",
    "        \"\"\"Convert profile to dictionary\"\"\"\n",
    "        return {\n",
    "            k: v for k, v in self.__dict__.items() \n",
    "            if isinstance(v, float)\n",
    "        }\n",
    "\n",
    "# Sample reviews for testing\n",
    "SAMPLE_REVIEWS = [\n",
    "    \"The food was incredibly sweet and sugary, almost too much so. Very creamy texture.\",\n",
    "    \"A perfectly spicy dish with great savory flavors. The meat was tender and juicy.\",\n",
    "    \"Excellent vegan options and gluten-free menu. The staff was super friendly.\",\n",
    "    \"The lighting was too dim and it was very noisy. The service was slow.\",\n",
    "    \"Fresh and crispy vegetables, perfectly seasoned. Clean and comfortable environment.\",\n",
    "    \"Not very flavorful and quite bitter. The texture was too chewy.\",\n",
    "    \"Amazing dairy-free alternatives. The dessert was smooth and silky.\",\n",
    "    \"The portions were huge and the price was reasonable. Very family-friendly place.\",\n",
    "    \"Authentic halal options. The meat was tender and well-spiced.\",\n",
    "    \"Great kosher menu with organic ingredients. The ambiance was romantic.\",\n",
    "    \"The sushi was fresh but a bit too salty. The seating was uncomfortable.\",\n",
    "    \"Perfect balance of sour and sweet in their signature cocktails.\",\n",
    "    \"The vegetables were crisp and the sauce was rich and creamy.\",\n",
    "    \"Very health-conscious menu with low-carb options. Clean environment.\",\n",
    "    \"Sustainable practices and eco-friendly packaging. Food was delicious.\",\n",
    "    \"The bread was soft and fluffy. Great vegetarian selection.\",\n",
    "    \"Excellent spice tolerance options from mild to very hot.\",\n",
    "    \"Beautiful plating and presentation. The food was lukewarm though.\",\n",
    "    \"Quick service and friendly staff. The restaurant was spotless.\",\n",
    "    \"Perfect for date night with intimate lighting and quiet atmosphere.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Taste Profile:\n",
      "Sweet: 0.08\n",
      "Salty: 0.67\n",
      "Spicy: 0.75\n",
      "Savory: 0.00\n",
      "Bitter: 0.00\n",
      "Sour: 0.54\n",
      "Crunchiness: 0.53\n",
      "Smoothness: 0.90\n",
      "Chewiness: 0.10\n",
      "Creaminess: 0.91\n",
      "Firmness: 0.50\n",
      "Juiciness: 0.66\n",
      "Softness: 0.71\n",
      "Gluten_free: 0.33\n",
      "Dairy_free: 0.14\n",
      "Vegan: 0.33\n",
      "Vegetarian: 0.06\n",
      "Nut_free: 0.00\n",
      "Shellfish_free: 0.00\n",
      "Price_sensitivity: 0.11\n",
      "Health_consciousness: 0.00\n",
      "Spice_tolerance: 0.66\n",
      "Sustainability_consciousness: 0.09\n",
      "Low_carb: 0.00\n",
      "Low_fat: 0.00\n",
      "Low_sugar: 0.00\n",
      "Organic: 0.10\n",
      "Halal: 0.00\n",
      "Kosher: 0.10\n",
      "Lighting_quality: 0.05\n",
      "Noise_level: 0.05\n",
      "Seating_comfort: 0.00\n",
      "Plating_aesthetics: 0.55\n",
      "Portion_size: 0.50\n",
      "Service_speed: 0.05\n",
      "Cleanliness: 0.00\n",
      "Temperature: 0.53\n",
      "Accessibility: 0.50\n",
      "Friendly_staff: 0.71\n",
      "Family_friendly: 0.56\n",
      "Romantic_ambiance: 0.57\n",
      "Top 10 Recommended Restaurants:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 163\u001b[0m\n\u001b[1;32m    115\u001b[0m             taste_profile\u001b[38;5;241m.\u001b[39mcuisine_profiles[cuisine] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    116\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: dish_name,\n\u001b[1;32m    117\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m: { \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 }\n\u001b[1;32m    160\u001b[0m             }\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Update the taste profile with hyper-specific cuisines\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m \u001b[43mupdate_cuisine_profiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaste_profile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Finding similar dishes\u001b[39;00m\n\u001b[1;32m    166\u001b[0m similar_dishes \u001b[38;5;241m=\u001b[39m find_similar_dishes(taste_profile)\n",
      "Cell \u001b[0;32mIn[5], line 156\u001b[0m, in \u001b[0;36mupdate_cuisine_profiles\u001b[0;34m(taste_profile)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cuisine, dishes \u001b[38;5;129;01min\u001b[39;00m HYPER_SPECIFIC_CUISINES\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dish_name, scores \u001b[38;5;129;01min\u001b[39;00m dishes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    115\u001b[0m         taste_profile\u001b[38;5;241m.\u001b[39mcuisine_profiles[cuisine] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: dish_name,\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m: { \n\u001b[1;32m    118\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msweet\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    119\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    120\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspicy\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m    121\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msavory\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m    122\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitter\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m    123\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msour\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m    124\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrunchiness\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m6\u001b[39m],\n\u001b[1;32m    125\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmoothness\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m7\u001b[39m],\n\u001b[1;32m    126\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchewiness\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m8\u001b[39m],\n\u001b[1;32m    127\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreaminess\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m9\u001b[39m],\n\u001b[1;32m    128\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirmness\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m    129\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjuiciness\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m11\u001b[39m],\n\u001b[1;32m    130\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftness\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m12\u001b[39m],\n\u001b[1;32m    131\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgluten_free\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m13\u001b[39m],\n\u001b[1;32m    132\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdairy_free\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m14\u001b[39m],\n\u001b[1;32m    133\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvegan\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m15\u001b[39m],\n\u001b[1;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvegetarian\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m16\u001b[39m],\n\u001b[1;32m    135\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnut_free\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m17\u001b[39m],\n\u001b[1;32m    136\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshellfish_free\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m18\u001b[39m],\n\u001b[1;32m    137\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_sensitivity\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m19\u001b[39m],\n\u001b[1;32m    138\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhealth_consciousness\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m20\u001b[39m],\n\u001b[1;32m    139\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspice_tolerance\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m21\u001b[39m],\n\u001b[1;32m    140\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msustainability_consciousness\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m22\u001b[39m],\n\u001b[1;32m    141\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_carb\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m23\u001b[39m],\n\u001b[1;32m    142\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_fat\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m24\u001b[39m],\n\u001b[1;32m    143\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_sugar\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m25\u001b[39m],\n\u001b[1;32m    144\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganic\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m26\u001b[39m],\n\u001b[1;32m    145\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhalal\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m27\u001b[39m],\n\u001b[1;32m    146\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkosher\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m28\u001b[39m],\n\u001b[1;32m    147\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlighting_quality\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m29\u001b[39m],\n\u001b[1;32m    148\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise_level\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m30\u001b[39m],\n\u001b[1;32m    149\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseating_comfort\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m31\u001b[39m],\n\u001b[1;32m    150\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplating_aesthetics\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m32\u001b[39m],\n\u001b[1;32m    151\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mportion_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m33\u001b[39m],\n\u001b[1;32m    152\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_speed\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m34\u001b[39m],\n\u001b[1;32m    153\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleanliness\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m35\u001b[39m],\n\u001b[1;32m    154\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m36\u001b[39m],\n\u001b[1;32m    155\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessibility\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m37\u001b[39m],\n\u001b[0;32m--> 156\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfriendly_staff\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m38\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    157\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfamily_friendly\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m39\u001b[39m],\n\u001b[1;32m    158\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mromantic_ambiance\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[\u001b[38;5;241m40\u001b[39m],\n\u001b[1;32m    159\u001b[0m             }\n\u001b[1;32m    160\u001b[0m         }\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# I now want to review the taste profile for this area\n",
    "\n",
    "# Function to view the taste profile\n",
    "def view_taste_profile(taste_profile: TasteProfile) -> None:\n",
    "    print(\"Current Taste Profile:\")\n",
    "    for attribute, score in taste_profile.to_dict().items():\n",
    "        print(f\"{attribute.capitalize()}: {score:.2f}\")\n",
    "\n",
    "# Function to recommend top 10 restaurants based on cuisine parameters\n",
    "def recommend_restaurants(cuisine_profiles: dict, top_n: int = 10) -> list:\n",
    "    recommendations = []\n",
    "    for cuisine, profile in cuisine_profiles.items():\n",
    "        # Assuming a function `get_top_restaurants` exists that fetches restaurants based on cuisine profile\n",
    "        top_restaurants = get_top_restaurants(cuisine, profile)\n",
    "        recommendations.extend(top_restaurants)\n",
    "    \n",
    "    # Sort and return the top N recommendations\n",
    "    return sorted(recommendations, key=lambda x: x['rating'], reverse=True)[:top_n]\n",
    "\n",
    "# Function to find the 10 most similar dishes to the initialized TasteProfile\n",
    "def find_similar_dishes(taste_profile: TasteProfile, top_n: int = 10) -> list:\n",
    "    similar_dishes = []\n",
    "    for cuisine, dishes in HYPER_SPECIFIC_CUISINES.items():\n",
    "        for dish_name, scores in dishes.items():\n",
    "            # Calculate similarity based on the distance between taste profile and dish scores\n",
    "            similarity_score = sum(\n",
    "                1 - abs(taste_profile.scores[attribute] - score) for attribute, score in zip(taste_profile.scores.keys(), scores)\n",
    "            )\n",
    "            similar_dishes.append((dish_name, similarity_score))\n",
    "    \n",
    "    # Sort by similarity score and return the top N similar dishes\n",
    "    return sorted(similar_dishes, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "# Viewing the taste profile\n",
    "view_taste_profile(taste_profile)\n",
    "\n",
    "# Getting recommendations\n",
    "top_restaurants = recommend_restaurants(taste_profile.cuisine_profiles)\n",
    "print(\"Top 10 Recommended Restaurants:\")\n",
    "for restaurant in top_restaurants:\n",
    "    print(f\"{restaurant['name']} - Rating: {restaurant['rating']}\")\n",
    "\n",
    "# Define a more compact way to handle hyper-specific cuisines\n",
    "HYPER_SPECIFIC_CUISINES = {\n",
    "    \"Italian\": {\n",
    "        \"Neapolitan Pizza\": [0.3, 0.5, 0.1, 0.9, 0.2, 0.4, 0.6, 0.5, 0.5, 0.4, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.4, 0.6, 0.8, 0.5, 0.5, 0.9, 0.5, 0.5, 0.5, 0.8, 0.6, 0.7],\n",
    "        \"Pasta Carbonara\": [0.4, 0.6, 0.2, 0.8, 0.1, 0.3, 0.5, 0.6, 0.7, 0.5, 0.6, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.7, 0.5, 0.5, 0.8, 0.5, 0.5, 0.5, 0.7, 0.6, 0.5],\n",
    "        \"Lasagna\": [0.5, 0.5, 0.3, 0.9, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.4, 0.6, 0.8, 0.5, 0.5, 0.9, 0.5, 0.5, 0.5, 0.8, 0.6, 0.7],\n",
    "        \"Fettuccine Alfredo\": [0.6, 0.4, 0.2, 0.8, 0.3, 0.5, 0.5, 0.7, 0.6, 0.4, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.7, 0.5, 0.5, 0.8, 0.5, 0.5, 0.5, 0.7, 0.6, 0.5],\n",
    "        \"Bruschetta\": [0.3, 0.5, 0.1, 0.9, 0.2, 0.4, 0.6, 0.5, 0.5, 0.4, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.4, 0.6, 0.8, 0.5, 0.5, 0.9, 0.5, 0.5, 0.5, 0.8, 0.6, 0.7]\n",
    "    },\n",
    "    \"Mexican\": {\n",
    "        \"Tacos\": [0.2, 0.5, 0.8, 0.7, 0.1, 0.6, 0.6, 0.4, 0.5, 0.5, 0.5, 0.7, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.8, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Mole\": [0.6, 0.4, 0.7, 0.8, 0.4, 0.2, 0.3, 0.8, 0.5, 0.6, 0.4, 0.7, 0.6, 0.8, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6, 0.5, 0.7, 0.6, 0.3, 0.4, 0.3, 0.7, 0.6, 0.5, 0.6, 0.5, 0.9, 0.7, 0.4, 0.8, 0.7, 0.6, 0.7],\n",
    "        \"Enchiladas\": [0.5, 0.5, 0.6, 0.7, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.6, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Chiles Rellenos\": [0.4, 0.6, 0.5, 0.8, 0.3, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Tamales\": [0.3, 0.5, 0.4, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5]\n",
    "    },\n",
    "    \"Japanese\": {\n",
    "        \"Sushi\": [0.5, 0.4, 0.2, 0.9, 0.3, 0.5, 0.5, 0.7, 0.6, 0.4, 0.5, 0.5, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.2, 0.9, 0.3, 0.7, 0.7, 0.8, 0.8, 0.7, 0.6, 0.5, 0.7, 0.4, 0.9, 0.6, 0.7, 0.9, 0.8, 0.6, 0.7],\n",
    "        \"Ramen\": [0.4, 0.5, 0.3, 0.8, 0.2, 0.5, 0.4, 0.6, 0.7, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.3, 0.5, 0.5, 0.5, 0.3, 0.4, 0.7, 0.4, 0.6, 0.5, 0.6, 0.6, 0.8, 0.8, 0.7, 0.8, 0.9, 0.6, 0.5],\n",
    "        \"Tempura\": [0.5, 0.5, 0.4, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Sashimi\": [0.4, 0.5, 0.3, 0.8, 0.2, 0.5, 0.4, 0.6, 0.7, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.3, 0.5, 0.5, 0.5, 0.3, 0.4, 0.7, 0.4, 0.6, 0.5, 0.6, 0.6, 0.8, 0.8, 0.7, 0.8, 0.9, 0.6, 0.5],\n",
    "        \"Udon\": [0.3, 0.5, 0.4, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5]\n",
    "    },\n",
    "    \"Indian\": {\n",
    "        \"Curry\": [0.4, 0.5, 0.9, 0.7, 0.2, 0.5, 0.5, 0.5, 0.5, 0.6, 0.5, 0.5, 0.5, 0.8, 0.0, 0.0, 0.7, 0.7, 1.0, 0.7, 0.6, 0.9, 0.6, 0.4, 0.5, 0.6, 0.5, 0.8, 0.5, 0.6, 0.5, 0.7, 0.7, 0.5, 0.8, 0.8, 0.6, 0.6],\n",
    "        \"Dosa\": [0.3, 0.4, 0.7, 0.6, 0.2, 0.4, 0.7, 0.4, 0.6, 0.3, 0.6, 0.4, 0.5, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.8, 0.7, 0.7, 0.7, 0.5, 0.6, 0.5, 0.6, 0.8, 0.5, 0.5, 0.6, 0.8, 0.7, 0.6, 0.7, 0.7, 0.7, 0.5],\n",
    "        \"Biryani\": [0.5, 0.5, 0.8, 0.7, 0.3, 0.5, 0.6, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Paneer Tikka\": [0.4, 0.5, 0.6, 0.7, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Samosa\": [0.3, 0.5, 0.7, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5]\n",
    "    },\n",
    "    \"Thai\": {\n",
    "        \"Pad Thai\": [0.5, 0.5, 0.7, 0.6, 0.2, 0.8, 0.6, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.5, 0.7, 0.5, 0.3, 0.4, 0.7, 0.5, 0.5, 0.5, 0.6, 0.6, 0.7, 0.7, 0.8, 0.7, 0.6, 0.6, 0.5],\n",
    "        \"Green Curry\": [0.4, 0.5, 0.8, 0.7, 0.2, 0.4, 0.4, 0.8, 0.5, 0.7, 0.4, 0.6, 0.6, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.6, 0.7, 0.8, 0.6, 0.5, 0.6, 0.5, 0.7, 0.5, 0.5, 0.6, 0.5, 0.8, 0.7, 0.6, 0.8, 0.8, 0.6, 0.6],\n",
    "        \"Tom Yum Soup\": [0.5, 0.5, 0.8, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.6, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Massaman Curry\": [0.4, 0.5, 0.7, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Spring Rolls\": [0.3, 0.5, 0.6, 0.7, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5]\n",
    "    },\n",
    "    \"French\": {\n",
    "        \"Bistro\": [0.6, 0.5, 0.2, 0.8, 0.3, 0.4, 0.5, 0.7, 0.5, 0.8, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.7, 0.0, 0.2, 0.5, 0.2, 0.5, 0.3, 0.3, 0.4, 0.6, 0.5, 0.5, 0.8, 0.4, 0.9, 0.7, 0.4, 0.9, 0.8, 0.6, 0.9],\n",
    "        \"Coq au Vin\": [0.3, 0.5, 0.2, 0.9, 0.2, 0.3, 0.4, 0.7, 0.6, 0.6, 0.5, 0.7, 0.7, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3, 0.6, 0.2, 0.5, 0.5, 0.4, 0.5, 0.6, 0.5, 0.5, 0.8, 0.4, 0.9, 0.8, 0.4, 0.8, 0.7, 0.6, 0.8],\n",
    "        \"Ratatouille\": [0.5, 0.5, 0.3, 0.8, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Bouillabaisse\": [0.4, 0.5, 0.4, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Crêpes\": [0.3, 0.5, 0.5, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5]\n",
    "    },\n",
    "    \"Ethiopian\": {\n",
    "        \"Injera with Wat\": [0.2, 0.4, 0.7, 0.8, 0.3, 0.6, 0.4, 0.6, 0.7, 0.4, 0.5, 0.6, 0.8, 0.0, 0.0, 0.7, 0.7, 0.8, 1.0, 0.8, 0.7, 0.7, 0.7, 0.4, 0.5, 0.5, 0.7, 0.8, 0.5, 0.6, 0.6, 0.7, 0.8, 0.5, 0.7, 0.7, 0.7, 0.6],\n",
    "        \"Tibs\": [0.2, 0.5, 0.6, 0.9, 0.2, 0.4, 0.5, 0.5, 0.7, 0.3, 0.7, 0.6, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7, 0.6, 0.6, 0.6, 0.6, 0.5, 0.6, 0.7, 0.8, 0.5, 0.6, 0.5, 0.8, 0.7, 0.5, 0.7, 0.8, 0.6, 0.6],\n",
    "        \"Doro Wat\": [0.3, 0.5, 0.6, 0.8, 0.2, 0.4, 0.5, 0.5, 0.7, 0.3, 0.7, 0.6, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7, 0.6, 0.6, 0.6, 0.6, 0.5, 0.6, 0.7, 0.8, 0.5, 0.6, 0.5, 0.8, 0.7, 0.5, 0.7, 0.8, 0.6, 0.6],\n",
    "        \"Kitfo\": [0.4, 0.5, 0.7, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Shiro\": [0.3, 0.5, 0.6, 0.7, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5]\n",
    "    },\n",
    "    \"Peruvian\": {\n",
    "        \"Ceviche\": [0.2, 0.4, 0.6, 0.7, 0.1, 0.9, 0.5, 0.6, 0.6, 0.3, 0.6, 0.8, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6, 0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.5, 0.5, 0.7, 0.5, 0.9, 0.6, 0.7, 0.8, 0.7, 0.6, 0.7],\n",
    "        \"Lomo Saltado\": [0.3, 0.6, 0.5, 0.8, 0.2, 0.4, 0.6, 0.5, 0.7, 0.4, 0.7, 0.7, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6, 0.6, 0.5, 0.6, 0.4, 0.5, 0.6, 0.6, 0.5, 0.5, 0.6, 0.6, 0.8, 0.8, 0.7, 0.7, 0.8, 0.6, 0.6],\n",
    "        \"Aji de Gallina\": [0.4, 0.5, 0.6, 0.7, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Pollo a la Brasa\": [0.5, 0.5, 0.7, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Tacu Tacu\": [0.3, 0.5, 0.6, 0.7, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5]\n",
    "    },\n",
    "    \"Korean\": {\n",
    "        \"Bibimbap\": [0.3, 0.5, 0.7, 0.8, 0.3, 0.5, 0.7, 0.5, 0.6, 0.4, 0.6, 0.6, 0.5, 0.0, 0.0, 0.0, 0.7, 0.8, 1.0, 0.7, 0.8, 0.7, 0.7, 0.5, 0.6, 0.6, 0.7, 0.5, 0.5, 0.6, 0.6, 0.9, 0.8, 0.7, 0.8, 0.7, 0.7, 0.5],\n",
    "        \"Korean BBQ\": [0.3, 0.6, 0.6, 0.9, 0.2, 0.4, 0.6, 0.4, 0.8, 0.3, 0.8, 0.7, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.6, 0.5, 0.6, 0.4, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.8, 0.7, 0.6, 0.8, 0.7, 0.6, 0.7],\n",
    "        \"Kimchi\": [0.4, 0.5, 0.6, 0.7, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Japchae\": [0.5, 0.5, 0.7, 0.6, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5],\n",
    "        \"Sundubu Jjigae\": [0.3, 0.5, 0.6, 0.7, 0.2, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6, 0.5, 0.5, 0.5, 0.7, 0.8, 0.5, 0.5, 0.8, 0.7, 0.5, 0.5, 0.5]\n",
    "    },\n",
    "    # Additional cuisines can be added here following the same structure\n",
    "}\n",
    "\n",
    "# Function to update cuisine profiles based on taste profiles\n",
    "def update_cuisine_profiles(taste_profile: TasteProfile) -> None:\n",
    "    for cuisine, dishes in HYPER_SPECIFIC_CUISINES.items():\n",
    "        for dish_name, scores in dishes.items():\n",
    "            taste_profile.cuisine_profiles[cuisine] = {\n",
    "                \"name\": dish_name,\n",
    "                \"scores\": { \n",
    "                    \"sweet\": scores[0],\n",
    "                    \"salty\": scores[1],\n",
    "                    \"spicy\": scores[2],\n",
    "                    \"savory\": scores[3],\n",
    "                    \"bitter\": scores[4],\n",
    "                    \"sour\": scores[5],\n",
    "                    \"crunchiness\": scores[6],\n",
    "                    \"smoothness\": scores[7],\n",
    "                    \"chewiness\": scores[8],\n",
    "                    \"creaminess\": scores[9],\n",
    "                    \"firmness\": scores[10],\n",
    "                    \"juiciness\": scores[11],\n",
    "                    \"softness\": scores[12],\n",
    "                    \"gluten_free\": scores[13],\n",
    "                    \"dairy_free\": scores[14],\n",
    "                    \"vegan\": scores[15],\n",
    "                    \"vegetarian\": scores[16],\n",
    "                    \"nut_free\": scores[17],\n",
    "                    \"shellfish_free\": scores[18],\n",
    "                    \"price_sensitivity\": scores[19],\n",
    "                    \"health_consciousness\": scores[20],\n",
    "                    \"spice_tolerance\": scores[21],\n",
    "                    \"sustainability_consciousness\": scores[22],\n",
    "                    \"low_carb\": scores[23],\n",
    "                    \"low_fat\": scores[24],\n",
    "                    \"low_sugar\": scores[25],\n",
    "                    \"organic\": scores[26],\n",
    "                    \"halal\": scores[27],\n",
    "                    \"kosher\": scores[28],\n",
    "                    \"lighting_quality\": scores[29],\n",
    "                    \"noise_level\": scores[30],\n",
    "                    \"seating_comfort\": scores[31],\n",
    "                    \"plating_aesthetics\": scores[32],\n",
    "                    \"portion_size\": scores[33],\n",
    "                    \"service_speed\": scores[34],\n",
    "                    \"cleanliness\": scores[35],\n",
    "                    \"temperature\": scores[36],\n",
    "                    \"accessibility\": scores[37],\n",
    "                    \"friendly_staff\": scores[38],\n",
    "                    \"family_friendly\": scores[39],\n",
    "                    \"romantic_ambiance\": scores[40],\n",
    "                }\n",
    "            }\n",
    "\n",
    "# Update the taste profile with hyper-specific cuisines\n",
    "update_cuisine_profiles(taste_profile)\n",
    "\n",
    "# Finding similar dishes\n",
    "similar_dishes = find_similar_dishes(taste_profile)\n",
    "print(\"Top 10 Similar Dishes:\")\n",
    "for dish, score in similar_dishes:\n",
    "    print(f\"{dish} - Similarity Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpAnalyzer:\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.data = None \n",
    "        self.clusters = None\n",
    "        self.cuisine_profiles = {}  # Maps cuisine types to typical taste profiles\n",
    "        self.neighborhood_profiles = {}  # Maps neighborhoods to aggregate taste profiles\n",
    "        \n",
    "    def run_analysis(self, metro_area: str):\n",
    "        \"\"\"Main function to run the full analysis pipeline\n",
    "        \n",
    "        TODO:\n",
    "        1. Implement proper error handling and logging\n",
    "        2. Add progress tracking\n",
    "        3. Consider parallel processing for large datasets\n",
    "        4. Add caching of intermediate results\n",
    "        \"\"\"\n",
    "        # Load and preprocess data\n",
    "        self.data = load_yelp_data(self.file_path)\n",
    "        self.data = filter_metropolitan_area(self.data, metro_area)\n",
    "        self.data = clean_data(self.data)\n",
    "        \n",
    "        # Run exploratory analysis\n",
    "        exploratory_data_analysis(self.data)\n",
    "        \n",
    "        # Extract and analyze taste profiles\n",
    "        taste_profiles = extract_taste_profiles(self.data)\n",
    "        self.cuisine_profiles = analyze_cuisine_profiles(taste_profiles, self.data)\n",
    "        \n",
    "        # Perform clustering and analysis\n",
    "        self.clusters = cluster_restaurants(self.data, taste_profiles)\n",
    "        self.neighborhood_profiles = analyze_neighborhood_profiles(self.clusters)\n",
    "        \n",
    "        # Validate results\n",
    "        known_boundaries = self._load_neighborhood_boundaries()\n",
    "        validation_results = validate_clusters(self.clusters, known_boundaries)\n",
    "        \n",
    "        return {\n",
    "            'clusters': self.clusters,\n",
    "            'cuisine_profiles': self.cuisine_profiles,\n",
    "            'neighborhood_profiles': self.neighborhood_profiles,\n",
    "            'validation': validation_results\n",
    "        }\n",
    "        \n",
    "    def recommend_cuisines(self, location: tuple):\n",
    "        \"\"\"Recommend cuisine types for a given location\n",
    "        \n",
    "        TODO:\n",
    "        1. Implement location-based profile matching\n",
    "        2. Add confidence scores to recommendations\n",
    "        3. Consider market saturation in recommendations\n",
    "        4. Add business viability metrics\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def _load_neighborhood_boundaries(self):\n",
    "        \"\"\"Load geographic boundary data for neighborhoods\n",
    "        \n",
    "        TODO:\n",
    "        1. Implement GeoJSON/shapefile parsing\n",
    "        2. Add caching of boundary data\n",
    "        3. Consider multiple data sources\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "def load_yelp_data(file_path: str):\n",
    "    \"\"\"Load and validate Yelp dataset\n",
    "    \n",
    "    TODO:\n",
    "    1. Implement efficient data loading for large files\n",
    "    2. Add data validation checks\n",
    "    3. Handle multiple file formats\n",
    "    4. Add data sampling options\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def filter_metropolitan_area(data, area: str):\n",
    "    \"\"\"Filter dataset for specific metro area\n",
    "    \n",
    "    TODO:\n",
    "    1. Implement geographic boundary checking\n",
    "    2. Add support for multiple areas\n",
    "    3. Consider demographic data integration\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def clean_data(data):\n",
    "    \"\"\"Clean and preprocess dataset\n",
    "    \n",
    "    TODO:\n",
    "    1. Implement text cleaning\n",
    "    2. Handle missing values\n",
    "    3. Remove duplicates\n",
    "    4. Normalize formats\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def exploratory_data_analysis(data):\n",
    "    \"\"\"Perform EDA on dataset\n",
    "    \n",
    "    TODO:\n",
    "    1. Generate basic statistics\n",
    "    2. Create visualizations\n",
    "    3. Identify outliers\n",
    "    4. Analyze data distributions\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def extract_taste_profiles(data):\n",
    "    \"\"\"Extract taste profiles from reviews\n",
    "    \n",
    "    TODO:\n",
    "    1. Implement NLP pipeline\n",
    "    2. Add sentiment analysis\n",
    "    3. Consider review weights\n",
    "    4. Handle multilingual content\n",
    "    \"\"\"\n",
    "    profiles = []\n",
    "    for review in data['reviews']:\n",
    "        profile = TasteProfile()\n",
    "        profile.update_scores(review)\n",
    "        profiles.append(profile)\n",
    "    return profiles\n",
    "\n",
    "def analyze_cuisine_profiles(profiles, data):\n",
    "    \"\"\"Analyze typical taste profiles for different cuisines\n",
    "    \n",
    "    TODO:\n",
    "    1. Implement cuisine categorization\n",
    "    2. Calculate aggregate profiles\n",
    "    3. Identify distinctive features\n",
    "    4. Consider regional variations\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def cluster_restaurants(data, profiles):\n",
    "    \"\"\"Cluster restaurants by taste and location\n",
    "    \n",
    "    TODO:\n",
    "    1. Implement clustering algorithm\n",
    "    2. Optimize parameters\n",
    "    3. Handle geographic constraints\n",
    "    4. Add cluster evaluation metrics\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def analyze_neighborhood_profiles(clusters):\n",
    "    \"\"\"Analyze taste profiles by neighborhood\n",
    "    \n",
    "    TODO:\n",
    "    1. Implement profile aggregation\n",
    "    2. Consider temporal trends\n",
    "    3. Add demographic analysis\n",
    "    4. Identify unique characteristics\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def validate_clusters(clusters, known_boundaries):\n",
    "    \"\"\"Validate clustering results\n",
    "    \n",
    "    TODO:\n",
    "    1. Implement validation metrics\n",
    "    2. Compare with external data\n",
    "    3. Add statistical tests\n",
    "    4. Generate validation reports\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
